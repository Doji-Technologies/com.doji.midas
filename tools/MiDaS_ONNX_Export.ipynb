{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyNmkFwzXwCZvPoGONER3n5b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Doji-Technologies/com.doji.midas/blob/master/tools/MiDaS_ONNX_Export.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYMldYci-taf"
      },
      "outputs": [],
      "source": [
        "# @title Environment Setup\n",
        "!git clone https://github.com/semjon00/MiDaS\n",
        "!git submodule add https://github.com/isl-org/Next-ViT midas/external/next_vit\n",
        "%cd MiDaS\n",
        "!pip install torch==1.13 torchvision==0.14.0\n",
        "!pip install timm==0.6.13\n",
        "!pip install einops==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Export all models to ONNX\n",
        "import cv2\n",
        "import torch\n",
        "import utils\n",
        "from midas.dpt_depth import DPTDepthModel\n",
        "from midas.midas_net_custom import MidasNet_small\n",
        "from midas.midas_net import MidasNet\n",
        "import os\n",
        "import requests\n",
        "import gc\n",
        "\n",
        "def download_file(url, folder_path):\n",
        "    # Create the folder if it doesn't exist\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "    # Get the file name from the URL\n",
        "    file_name = url.split(\"/\")[-1]\n",
        "\n",
        "    # Combine the folder path and file name to get the full file path\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "    # Check if the file already exists in the folder\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"File already downloaded: {file_path}\")\n",
        "    else:\n",
        "        # Send an HTTP GET request to the URL\n",
        "        response = requests.get(url)\n",
        "\n",
        "        # Check if the request was successful\n",
        "        if response.status_code == 200:\n",
        "            # Open the file and write the content from the response\n",
        "            with open(file_path, 'wb') as file:\n",
        "                file.write(response.content)\n",
        "            print(f\"File downloaded and saved to: {file_path}\")\n",
        "        else:\n",
        "            print(f\"Failed to download the file. HTTP status code: {response.status_code}\")\n",
        "\n",
        "\n",
        "def patchUnflatten():\n",
        "    import torch.nn as nn\n",
        "\n",
        "    class View(nn.Module):\n",
        "        def __init__(self, dim,  shape):\n",
        "            super(View, self).__init__()\n",
        "            self.dim = dim\n",
        "            self.shape = shape\n",
        "\n",
        "        def forward(self, input):\n",
        "            new_shape = list(input.shape)[:self.dim] + list(self.shape) + list(input.shape)[self.dim+1:]\n",
        "            return input.view(*new_shape)\n",
        "\n",
        "    nn.Unflatten = View\n",
        "\n",
        "model_params = [\n",
        "    {\n",
        "        \"name\": \"dpt_beit_large_512\",\n",
        "        \"path\": \"weights/dpt_beit_large_512.pt\",\n",
        "        \"backbone\": \"beitl16_512\",\n",
        "        \"url\": \"https://github.com/isl-org/MiDaS/releases/download/v3_1/dpt_beit_large_512.pt\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"dpt_beit_large_384\",\n",
        "        \"path\": \"weights/dpt_beit_large_384.pt\",\n",
        "        \"backbone\": \"beitl16_384\",\n",
        "        \"url\": \"https://github.com/isl-org/MiDaS/releases/download/v3_1/dpt_beit_large_384.pt\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"dpt_beit_base_384\",\n",
        "        \"path\": \"weights/dpt_beit_base_384.pt\",\n",
        "        \"backbone\": \"beitb16_384\",\n",
        "        \"url\": \"https://github.com/isl-org/MiDaS/releases/download/v3_1/dpt_beit_base_384.pt\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"dpt_swin2_large_384\",\n",
        "        \"path\": \"weights/dpt_swin2_large_384.pt\",\n",
        "        \"backbone\": \"swin2l24_384\",\n",
        "        \"url\": \"https://github.com/isl-org/MiDaS/releases/download/v3_1/dpt_swin2_large_384.pt\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"dpt_swin2_base_384\",\n",
        "        \"path\": \"weights/dpt_swin2_base_384.pt\",\n",
        "        \"backbone\": \"swin2b24_384\",\n",
        "        \"url\": \"https://github.com/isl-org/MiDaS/releases/download/v3_1/dpt_swin2_base_384.pt\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"dpt_swin2_tiny_256\",\n",
        "        \"path\": \"weights/dpt_swin2_tiny_256.pt\",\n",
        "        \"backbone\": \"swin2t16_256\",\n",
        "        \"url\": \"https://github.com/isl-org/MiDaS/releases/download/v3_1/dpt_swin2_tiny_256.pt\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"dpt_swin_large_384\",\n",
        "        \"path\": \"weights/dpt_swin_large_384.pt\",\n",
        "        \"backbone\": \"swinl12_384\",\n",
        "        \"url\": \"https://github.com/isl-org/MiDaS/releases/download/v3_1/dpt_swin_large_384.pt\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"dpt_next_vit_large_384\",\n",
        "        \"path\": \"weights/dpt_next_vit_large_384.pt\",\n",
        "        \"backbone\": \"next_vit_large_6m\",\n",
        "        \"url\": \"https://github.com/isl-org/MiDaS/releases/download/v3_1/dpt_next_vit_large_384.pt\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"dpt_levit_224\",\n",
        "        \"path\": \"weights/dpt_levit_224.pt\",\n",
        "        \"backbone\": \"levit_384\",\n",
        "        \"url\": \"https://github.com/isl-org/MiDaS/releases/download/v3_1/dpt_levit_224.pt\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"dpt_large_384\",\n",
        "        \"path\": \"weights/dpt_large_384.pt\",\n",
        "        \"backbone\": \"vitl16_384\",\n",
        "        \"url\": \"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_large_384.pt\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"midas_v21_384\",\n",
        "        \"path\": \"weights/midas_v21_384.pt\",\n",
        "        \"backbone\": \"\",\n",
        "        \"url\": \"https://github.com/isl-org/MiDaS/releases/download/v2_1/midas_v21_384.pt\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"midas_v21_small_256\",\n",
        "        \"path\": \"weights/midas_v21_small_256.pt\",\n",
        "        \"backbone\": \"\",\n",
        "        \"url\": \"https://github.com/isl-org/MiDaS/releases/download/v2_1/midas_v21_small_256.pt\"\n",
        "    },\n",
        "]\n",
        "\n",
        "for model_param in reversed(model_params):\n",
        "    onnxFile = \"weights/\" + model_param[\"name\"] + \".onnx\"\n",
        "    if os.path.exists(onnxFile):\n",
        "        print(f\"ONNX model for {model_param['name']} already exists. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    patchUnflatten()\n",
        "    download_file(model_param[\"url\"], \"weights\")\n",
        "    model_path = model_param[\"path\"]\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "    if model_param[\"name\"] == \"dpt_levit_224\":\n",
        "        model = DPTDepthModel(\n",
        "            path=model_path,\n",
        "            backbone=model_param[\"backbone\"],\n",
        "            non_negative=True,\n",
        "            head_features_1=64,\n",
        "            head_features_2=8,\n",
        "        )\n",
        "    elif model_param[\"name\"] == \"midas_v21_384\":\n",
        "        model = MidasNet(model_path, non_negative=True)\n",
        "    elif model_param[\"name\"] == \"midas_v21_small_256\":\n",
        "        model = MidasNet_small(\n",
        "            model_path,\n",
        "            features=64,\n",
        "            backbone=\"efficientnet_lite3\",\n",
        "            exportable=True,\n",
        "            non_negative=True,\n",
        "            blocks={'expand': True})\n",
        "    else:\n",
        "        model = DPTDepthModel(\n",
        "            path=model_path,\n",
        "            backbone=model_param[\"backbone\"],\n",
        "            non_negative=True,\n",
        "        )\n",
        "\n",
        "    if model_param[\"name\"] == \"dpt_swin2_tiny_256\" or model_param[\"name\"] == \"midas_v21_small_256\":\n",
        "        net_w, net_h = 256, 256\n",
        "    elif model_param[\"name\"] == \"dpt_levit_224\":\n",
        "        net_w, net_h = 224, 224\n",
        "    else:\n",
        "        net_w, net_h = 384, 384\n",
        "\n",
        "    #resize_mode = \"minimal\"\n",
        "    #normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "\n",
        "    #resize_image = Resize(\n",
        "    #    net_w,\n",
        "    #    net_h,\n",
        "    #    resize_target=None,\n",
        "    #    keep_aspect_ratio=False,\n",
        "    #    ensure_multiple_of=32,\n",
        "    #    resize_method=\"upper_bound\",\n",
        "    #    image_interpolation_method=cv2.INTER_CUBIC,\n",
        "    #)\n",
        "\n",
        "    #transform = Compose(\n",
        "    #    [\n",
        "    #        resize_image,\n",
        "    #        normalization,\n",
        "    #        PrepareForNet()\n",
        "    #    ]\n",
        "    #)\n",
        "    model.eval()\n",
        "\n",
        "    #img = utils.read_image(\"input/dog.jpg\")\n",
        "    #img_input = transform({\"image\": img})[\"image\"]\n",
        "    #shaped = img_input.reshape(1, 3, net_h, net_w)\n",
        "    torch.onnx.export(model, torch.rand(1, 3, net_h, net_w, dtype=torch.float), onnxFile, export_params=True)\n",
        "\n",
        "    # free memory\n",
        "    del model\n",
        "    gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCp7VHWwAcHp",
        "outputId": "22029bd8-f306-4863-a414-4848a476c643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX model for midas_v21_small_256 already exists. Skipping...\n",
            "ONNX model for midas_v21_384 already exists. Skipping...\n",
            "ONNX model for dpt_large_384 already exists. Skipping...\n",
            "ONNX model for dpt_levit_224 already exists. Skipping...\n",
            "ONNX model for dpt_next_vit_large_384 already exists. Skipping...\n",
            "ONNX model for dpt_swin_large_384 already exists. Skipping...\n",
            "ONNX model for dpt_swin2_tiny_256 already exists. Skipping...\n",
            "ONNX model for dpt_swin2_base_384 already exists. Skipping...\n",
            "ONNX model for dpt_swin2_large_384 already exists. Skipping...\n",
            "ONNX model for dpt_beit_base_384 already exists. Skipping...\n",
            "ONNX model for dpt_beit_large_384 already exists. Skipping...\n",
            "File already downloaded: weights/dpt_beit_large_512.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/content/MiDaS/midas/backbones/beit.py:80: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  window_size = tuple(np.array(resolution) // 16)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Copy to Google Drive\n",
        "!pip install google-colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the source folder containing files with the specific extension\n",
        "source_folder = 'weights/'\n",
        "\n",
        "# Define the target folder in your Google Drive where you want to copy the files\n",
        "target_folder = '/content/drive/MyDrive/MiDaS_Models/'\n",
        "\n",
        "# Ensure the target folder exists, or create it if it doesn't\n",
        "if not os.path.exists(target_folder):\n",
        "    os.makedirs(target_folder)\n",
        "\n",
        "# Specify the file extension you're looking for\n",
        "file_extension = '.onnx'\n",
        "\n",
        "# Get a list of files in the target folder\n",
        "target_files = os.listdir(target_folder)\n",
        "\n",
        "# Iterate over files in the source folder\n",
        "for root, dirs, files in os.walk(source_folder):\n",
        "    for file in files:\n",
        "        if file.endswith(file_extension):\n",
        "            source_path = os.path.join(root, file)\n",
        "            target_path = os.path.join(target_folder, file)\n",
        "            # Copy the file to Google Drive only if it doesn't already exist\n",
        "            if file not in target_files:\n",
        "                shutil.copy(source_path, target_path)\n",
        "                print(f'Copied {file} to Google Drive.')\n",
        "\n",
        "print(f'Copied all {file_extension} files to Google Drive.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8uCfEwqjI0A",
        "outputId": "26880496-5a9d-45c4-d425-70e3fbc3fb1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Copied dpt_beit_large_512.onnx to Google Drive.\n",
            "Copied dpt_beit_large_384.onnx to Google Drive.\n",
            "Copied dpt_beit_base_384.onnx to Google Drive.\n",
            "Copied all .onnx files to Google Drive.\n"
          ]
        }
      ]
    }
  ]
}